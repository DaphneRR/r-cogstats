<!--- Time-stamp: <2013-11-24 19:32:50 chl> -->

<!--- To generate HTML output:
library(knitr)
library(markdown)
knit("hmisc.rmd", quiet=TRUE)
markdownToHTML("hmisc.md", "hmisc.html", stylesheet="styles.css", option=c("highlight_code", "toc"), title="Hmisc and rms")
browseURL("hmisc.html")
-->


```{r setup, include=FALSE}
opts_knit$set(progress=FALSE, verbose=FALSE, width=90)
opts_chunk$set(message=FALSE, tidy=TRUE, highlight=TRUE, fig.align="center")
library(latticeExtra)
trellis.par.set(custom.theme.2())
trellis.par.set(plot.symbol=list(pch=19, cex=1.2),
                strip.background = list(col = "transparent"), 
                fontsize = list(text = 16, points = 8))
```

<p style="font-size: 200%; font-weight: bold; text-align: center;">The Hmisc and rms packages</p>

The [Hmisc][1] and [rms][2] packages provide a wide range of tools for data
transformation, aggregated visual and numerical summaries, and enhanced R's
output for most common biostatistical models (linear regression, logistic or
Cox regression).


## Data preparation

Text-based data file (comma- or tab-delimited files) can be imported using
`read.csv()` or the more generic command `read.table()`. The [foreign][3]
package can be used to process binary data files from other statistical
packages. See also [R Data Import/Export][4]. `Hmisc` offers extended
support for foreign data files, including CSV (`csv.get()`), SAS
(`sas.get()`), SPSS (`spss.get()`), or Stata (`stata.get()`). Variables
names are automatically converted to lowercase, dates are generally better
handled. Documentation and additional information on the
[Hmisc website][5]. Various dataset can be download from a
[public repository][6] via the `getHdata()` command.

As always, before using any package in R, it must be loaded first:
```{r hmisc, eval=1}
library(Hmisc)
help(package=Hmisc)
```

In what follows, we will be using `birthwt` data set from the `MASS`
package. The low birth weight study is one of the datasets used throughout
Hosmer and Lemeshow's textbook on Applied Logistic Regression (2000, Wiley,
2nd ed.). The goal of this prospective study was to identify risk factors
associated with giving birth to a low birth weight baby (weighing less than
2,500 grams). Data were collected on 189 women, 59 of which had low birth
weight babies and 130 of which had normal birth weight babies. Four
variables which were thought to be of importance were age, weight of the
subject at her last menstrual period, race, and the number of physician
visits during the first trimester of pregnancy. It can be loaded as shown
below:
```{r birthwt, eval=1}
data(birthwt, package="MASS")
help(birthwt)
```

In this data set there is no missing observations, but let introduce
some `NA` values. Note that variable names are relatively short and poorly
informative. Shorter names are, however, easy to manipulate with R. `Hmisc`
provides specific command for labeling (`label()`) and adding units of
measurement (`units()`) as additional attributes to a given variable (or
data frame). We will also convert some of the variables as factor with
proper label (rather than 0/1 values) to facilitate reading of summary
tables or subsequent graphics.
```{r missing}
birthwt$age[5] <- NA
birthwt$ftv[sample(1:nrow(birthwt), 5)] <- NA
yesno <- c("No", "Yes")
birthwt <- within(birthwt, {
  smoke <- factor(smoke, labels=yesno)
  low <- factor(low, labels=yesno)
  ht <- factor(ht, labels=yesno)
  ui <- factor(ui, labels=yesno)
  race <- factor(race, levels=1:3, labels=c("White", "Black", "Other"))
  lwt <- lwt/2.2  ## weight in kg
})
label(birthwt$age) <- "Mother age"
units(birthwt$age) <- "years"
label(birthwt$bwt) <- "Baby weight"
units(birthwt$bwt) <- "grams"
label(birthwt, self=TRUE) <- "Hosmer & Lemeshow's low birth weight study."
list.tree(birthwt)  ## equivalent to str(birthwt)
```

The last command, `list.tree()`, offers a convenient replacement for R's
`str()`, and in addition to variable type and a list of the first
observation for each variable it will display `Hmisc` labels associated to
them. 

The `contents()` command offers a quick summary of data format and missing
values, and it provides a list of labels associated to variables treated as
factor by R.
```{r contents}
contents(birthwt)
```

Another useful command is `describe()`, which gives detailed summary
statistics for each variable in a given data frame. It can be printed as
HTML, or as PDF (by using the `latex()` backend), and in the latter case
small graphics are added that depict distribution of continuous variables.
```{r describe}
describe(birthwt, digits=3)
```

Of course, it is also possible to describe only a subset of the data or
specific data.
```{r subset, eval=FALSE}
describe(subset(birthwt, select=c(age, race, bwt, low)))
```

`Hmisc` has several helper functions to work with categorical variables,
like `dropUnusedLevels()` to remove missing levels or `Cs()` to convert
unquoted list of variables names to characters. It also provides a
replacement for R's `cut()` function with better default options (especially
the infamous `include.lowest=FALSE`) to discretize a continuous
variable. Here are some examples of use:
```{r cut2}
table(cut2(birthwt$lwt, g=4))
table(cut2(birthwt$age, g=3, levels.mean=TRUE))
```

Using `levels.mean=TRUE` will return class center, instead of class
intervals.

There are also a bunch of command dedicated to variables clustering,
analysis of missing patterns, or simple (`impute()`) or multiple
(`aregImpute()`, `transcan()`) imputation methods. Here is how we would
impute missing values with the median in the case of a continuous variable: 
```{r impute}
lwt <- birthwt$lwt
lwt[sample(length(lwt), 10)] <- NA
lwt.i <- impute(lwt)
summary(lwt.i)
```

Missing observations will be marked with an asterisk when we print the whole
object in R. To use the mean instead of the median, we just have to add the
`fun=mean` option.



## Visual and numerical summaries

There are three useful commands that provide summary statistics for a list of
variables. They implement the [split-apply-combine strategy][7] in the spirit
of R's built-in functions (unlike [plyr][8]).

The first one, `summarize()`, can be seen as an equivalent to R's
`aggregate()` command. Given a response variable and one or more
classification factors, it applies a specific function to all data chunk,
where each chunk is defined based on factor levels. The results are stored
in a matrix, which can easily be coerced to a data frame (`as.data.frame()`
or `Hmisc::matrix2dataFrame()`).

*Remark:* Some of the results are shown via the `prn()` command.

```{r summarize, echo=1:2}
f <- function(x, na.opts=TRUE) c(mean=mean(x, na.rm=na.opts), sd=sd(x, na.rm=na.opts))
out <- with(birthwt, summarize(bwt, race, f))
prn(out, "Average baby weight by ethnicity")
```

Contrary to `aggregate()`, this command provides multiway data structure in
case we ask to compute more than one quantity, as the following command will
confirm: 
```{r }
dim(out)  ## should have 3 columns
dim(aggregate(bwt ~ race, data=birthwt, f))
```

Summarizing multivariate responses or predictors is also possible, with
either `summarize()` or `mApply()`. Of course, any built-in functions, such
as `colMeans()` could be used in place of our custom summary command.
```{r }
with(birthwt, summarize(bwt, llist(race, smoke), f))
```

The second command, `bystats()`, (or `bystats2()` for two-way tabular
output) allows to describe with any custom or built-in function one or
multiple outcome by two explanatory variables, or even more. Sample size and
the number of missing values are also printed.
```{r bystats}
with(birthwt, bystats(cbind(bwt, lwt), smoke, race))
with(birthwt, bystats2(lwt, smoke, race))
```

The third and last command is `summary.formula()`, which can be abbreviated
as `summary()` as long as formula is used to describe variables
relationships. There are three main configurations (`method=`):
`"response"`, where a numerical variable is summarized for each level of
one or more variables (numerical variables will be discretized in 4
classes), as `summarize()` does; `"cross"`, to compute conditional and
marginal means of several response variables described by at most 3
explanatory variables (again, continuous predictors are represented as
quartiles); `"reverse"`, to summarize univariate distribution of a set of
variables for each level of a classification variable (which appears on the
left-hand side of the formula). Variables are viewed as continuous as long
as they have more than 10 distinct values, but this can be changed by
setting, e.g., `continuous=5`. With `method="reverse"`, it is possible to
add `overall=TRUE, test=TRUE` to add overall statistics and corresponding
statistical tests of null effect between the groups.

Here are some examples of use.
```{r summary}
summary(bwt ~ race + ht + lwt, data=birthwt)
summary(cbind(lwt, age) ~ race + bwt, data=birthwt, method="cross")
summary(low ~ race + ht, data=birthwt, fun=table)
out <- summary(low ~ race + age + ui, data=birthwt, method="reverse", overall=TRUE, test=TRUE)
print(out, prmsd=TRUE, digits=2)
```

Note also that tabular output can be converted to graphical displays by
using `plot()` like in, e.g.,

```{r plot_summary_reverse}
plot(out, which="categorical")
```

`Hmisc` provides replacement for some [lattice][9] commands, in particular
`xYplot()` and `dotchart2()`, or `Dotplot()`. In fact, it is also its
strength because we do not need to learn [ggplot2][10] to overcome base
graphics limitations, and using `Hmisc` keep in line with lattice charts
(and their multiple options).

Let say we would like to display average birth weight plus or minus one
standard error for each class of mother ethnicity. Assuming there is no
missing variable we could define a simple function that returns means and
associated lower/upper bounds.
```{r xyplot, echo=c(1:3,5), fig.show="hide", message=FALSE}
se <- function(x) sd(x)/sqrt(length(x))
f <- function(x) c(mean=mean(x), lwr=mean(x)-se(x), upr=mean(x)+se(x))
d <- with(birthwt, summarize(bwt, race, f))
prn(d, "Summary statistics (Mean +/- SE) by group")
xYplot(Cbind(bwt, lwr, upr) ~ numericScale(race, label="Ethnicity"),
       data=d, type="b", keys="lines", ylim=range(apply(d[,3:4], 2, range))+c(-1,1)*100,
       scales = list(x=list(at = 1:3, labels = levels(d$race))))
```

An easier (also shorter) solution is to rely on `lattice` extra commands, like
```{r segplot, fig.height=5}
library(latticeExtra)
segplot(race ~ lwr + upr, data=d, centers=bwt, horizontal=FALSE,
draw.bands=FALSE, ylab="Baby weight (g)")
```
although `xYplot()` is very handy when processing model predictions
generated by `ols()` or `lrm()`, as we will discuss below.


`Hmisc` provides automatic labelling of curves or levels of grouping factor,
which are used as in standard lattice graphics (`groups=`), without the need
to rely on the [directlabels][11] package.
```{r directlabels, fig.height=5}
d <- with(birthwt, summarize(bwt, llist(race, smoke), f))
xYplot(Cbind(bwt, lwr, upr) ~ numericScale(race), groups=smoke,
       data=d, type="l", keys="lines", method="alt bars", ylim=c(2200, 3600),
	   scales = list(x=list(at = 1:3, labels = levels(d$race))))
```


## Model fitting and diagnostic

The [rms][2] package is used in combination with `Hmisc`, which takes care
of data pre-processing and statistical summary. It is devoted to model
fitting, including validation (`validate()`) and calibration (`calibrate()`)
using bootstrap. It further includes utilities to refine general modeling
strategies and to handle higher-order terms (polymonial or restricted cubic
splines) or ordered catgeorical predictors, see online
`help(rms.trans)`. The definitive guide to regression modeling using `rms` is

> Harrell, F.E., Jr (2001). *Regression Modeling Strategies, With Applications
> to Linear Models, Logistic Regression, and Survival Analysis*. Springer.

The companion website is [BIOS 330: Regression Modeling Strategies][12].

Instead of `lm()`, we will use `ols()` to perform linear regression, but the
general formulation of the parametric model remains the same: a formula is
used to describe variable relationships (the response variable is on the
left-hand side, while predictors are on the right-hand side). A basic usage
of this command is shown below. To reuse the model for predictions purpose,
the linear predictor must be stored with model results (`x=TRUE`).
```{r ols}
library(rms)
m <- ols(bwt ~ age + race + ftv, data=birthwt, x=TRUE)
m
```

Note that, contrary to `lm()`, the `summary()` method (or more precisely,
`summary.rms()`) does something else. With `ols()` it will print a summary
of the effect of each factor. It requires, however, that the user create a
`datadist` object to store values for the predictors entering the
model, and that object must be available in the current namespace. So, the
preceding example becomes: 

```{r datadist}
d <- datadist(birthwt)
options(datadist="d")
m <- ols(bwt ~ age + race + ftv, data=birthwt, x=TRUE)
summary(m)
```

Effect size measures can also be displayed graphically using the
corresponding `plot` method:
```{r plot_summary, fig.height=4}
plot(summary(m))
```
Note also that in the case of multiple regression it is possible to select
baseline category and adjust the effect for a particular value of a
continuous predictor, as in the example below.
```{r summary_effect}
summary(m, race="Other", age=median(birthwt$age))
```

A more conventional ANOVA table for the regression can be obtained using
`anova()`.
```{r anova}
anova(m)
```

Measures of influence are available with the `which.influence()` command,
and it returns observations that are above a certain threshold with respect
to their DFBETA (default, 0.2). The `vif()` command displays variance
inflation factor, which can be used to gauge multicolinearity issue.
```{r influence}
which.influence(m)
vif(m)
```

Model predictions are carried out the R's way, using `fitted()`, or
`rms::Predict`. The latter offers additional control over adjustment factor
(like the [effects][13] package does), and does not require to create a data
frame as in `predict()`. It also handles 95% confidence intervals smoothly.
```{r predict, fig.height=5}
p <- Predict(m, age=seq(20, 35, by=5), race, ftv=1)
xYplot(Cbind(yhat,lower,upper) ~ age | race, data=p, layout=c(3,1),
       method="filled bands", type="l", col.fill=gray(.95))
```

Logistic regression is handled by the `lrm()` function, and it works almost
in the same way, except that it provides more convenient output than R's
`glm()`, especially in terms of adjusted odds-ratio, partial effects,
confidence intervals, or likelihhod ratio test.

[1]: http://cran.r-project.org/web/packages/Hmisc
[2]: http://cran.r-project.org/web/packages/rms
[3]: http://cran.r-project.org/web/packages/foreign
[4]: http://cran.r-project.org/doc/manuals/r-release/R-data.html
[5]: http://biostat.mc.vanderbilt.edu/wiki/Main/Hmisc
[6]: http://biostat.mc.vanderbilt.edu/wiki/Main/DataSets
[7]: http://www.jstatsoft.org/v40/i01/
[8]: http://plyr.had.co.nz/
[9]: http://cran.r-project.org/web/packages/lattice
[10]: http://ggplot2.org/
[11]: http://cran.r-project.org/web/packages/directlabels
[12]: http://biostat.mc.vanderbilt.edu/wiki/Main/CourseBios330
[13]: http://cran.r-project.org/web/packages/effects


<!---






\section*{Pour aller plus loin}
Il existe un très bon tutoriel sur \verb|Hmisc| (anciennement
\verb|Design|), \emph{An Introduction to S and the Hmisc and Design Libraries; CF
Alzola and FE Harrell} (PDF, 310 pages), disponible à l'adresse suivante :
\url{http://biostat.mc.vanderbilt.edu/Hmisc}. On y trouvera également
d'autres resources documentaires. 

La référence bibliographique concernant le package \verb|rms| est :
\begin{quote}
  Harrell, F.E., Jr (2001). \emph{Regression Modeling Strategies, With
  Applications to Linear Models, Logistic Regression, and Survival Analysis.}
  Springer. (600 pages)
\end{quote}
Le cours en ligne suivant repose cet ouvrage et fournit l'essentiel des
idées dans un document PDF :
\url{http://biostat.mc.vanderbilt.edu/wiki/Main/CourseBios330}. Le livre
\emph{Clinical Prediction Models} de E.W. Steyerberg repose en partie sur le
package \verb|rms| et constitue un bon complément à l'ouvrage ci-dessus. Le
site companion du livre est : \url{http://www.clinicalpredictionmodels.org}.
-->
